{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.preprocessing import StandardScaler\r\n",
    "import matplotlib.pyplot as plt "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Questão 1"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Considere o conjunto de dados disponível em concrete.csv, organizado em 9 colunas, sendo as 8 primeiras colunas os atributos e a última coluna a saída. Os 8 atributos referem-se à caracterização de diferentes tipos de concreto para construção civil. A saída é a resistência à compressão do concreto (em megapascals, MPa). Maiores detalhes sobre os dados podem ser conferidos em https://www.openml.org/d/4353"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "dataset = np.genfromtxt('./concrete.csv', delimiter=',', skip_header=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### a) Considere um modelo de regressão não linear baseado em redes neurais arti\u001cciais. Separe os dados aleatoriamente em treino, validação e teste(por exemplo, 60%, 20% e 20%). Nesse cenário, treine e avalie o modelo abaixo:  "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "source": [
    "x_train, x_test_tmp, y_train, y_test_tmp = train_test_split(dataset[:,:-1],dataset[:,-1],train_size=0.6)\r\n",
    "x_val, x_test,y_val, y_test = train_test_split(x_test_tmp,y_test_tmp, train_size=0.5)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### MLP (multilayer perceptron): 1 camada oculta e treinamento em minibatch via gradiente descendente estocástico com termo de momentum. Utilize o conjunto de validação para ajustar os hiperparâmetros. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "source": [
    "#inicias hiper parametros\r\n",
    "minibatch = 20\r\n",
    "momentum = 0.9\r\n",
    "alpha = 0.01\r\n",
    "hidden_nodes = 10\r\n",
    "epoches = 200\r\n",
    "#weigh_decay = 0"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "source": [
    "#normalizar dados\r\n",
    "nomalizador_x = StandardScaler().fit(x_train)\r\n",
    "x_train = nomalizador_x.transform(x_train)\r\n",
    "x_val = nomalizador_x.transform(x_val)\r\n",
    "\r\n",
    "nomalizador_y = StandardScaler().fit(y_train.reshape(-1,1))\r\n",
    "y_train = nomalizador_y.transform(y_train.reshape(-1,1))\r\n",
    "y_val = nomalizador_y.transform(y_val.reshape(-1,1))\r\n",
    "\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "source": [
    "x_ = np.c_[np.ones(x_train.shape[0]),x_train]\r\n",
    "W = np.zeros((hidden_nodes+1,x_train.shape[1]+1))\r\n",
    "K = 1\r\n",
    "j_history = []\r\n",
    "m = np.zeros((hidden_nodes+1))\r\n",
    "m[0] = np.mean(y_train)\r\n",
    "\r\n",
    "for epoch in range(epoches):\r\n",
    "    '''z_ = []\r\n",
    "    for nh in range(hidden_nodes):\r\n",
    "        zs = []      \r\n",
    "        for i in range(x_.shape[0]):\r\n",
    "            u = W[nh].T@x_[i]\r\n",
    "            z = np.tanh(u)            \r\n",
    "            zs.append(z)\r\n",
    "        z_.append(zs)\r\n",
    "    '''  \r\n",
    "    z_ = []\r\n",
    "    u_ = []  \r\n",
    "    for nh in range(hidden_nodes+1):\r\n",
    "        if nh == 0:\r\n",
    "            u = W[nh]@x_\r\n",
    "            z = np.vstack(np.ones((1, u.shape[1])),np.tanh(u))\r\n",
    "        elif h < hidden_nodes:\r\n",
    "            u = W[nh] @ z_[nh-1]\r\n",
    "            z = np.vstack(np.ones((1, u.shape[1])),np.tanh(u))\r\n",
    "        else:\r\n",
    "            u = W[nh] @ z_[nh-1]\r\n",
    "            z = np.tanh(u)\r\n",
    "        u_.append(u)\r\n",
    "        z_.append(z)\r\n",
    "\r\n",
    "    z_ = np.array(z_)\r\n",
    "    #z_ = np.concatenate((np.ones(x_.shape[0]).reshape(1,-1),z_),axis=0)\r\n",
    "    \r\n",
    "    \r\n",
    "    o = m.T@z_ \r\n",
    "\r\n",
    "    #Calcula o erro\r\n",
    "    e = (y_train-o.reshape(-1,1))    \r\n",
    "    j = np.sum((y_train- o.reshape(-1,1))**2)/(2*x_train.shape[0])    \r\n",
    "    j_history.append(j)\r\n",
    "\r\n",
    "    #atualiza os parametros    \r\n",
    "    m += (alpha * e[:,0].T)@ z_.T    \r\n",
    "    ç = ((1-z_**2).T * m).T *e[:,0]\r\n",
    "    #print(ç[].shape, x_.shape, alpha)\r\n",
    "    W += ((ç@x_)*alpha)\r\n",
    "    \r\n",
    "    \r\n",
    "#minibatch\r\n",
    "#momentum\r\n",
    "#prev\r\n",
    "#validacao\r\n",
    "#test\r\n"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 618 is different from 9)",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23268/1409429674.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mnh\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_nodes\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnh\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m             \u001b[0mu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mW\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnh\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m@\u001b[0m\u001b[0mx_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m             \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mh\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mhidden_nodes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 618 is different from 9)"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "source": [],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([2.08166817e-17, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00])"
      ]
     },
     "metadata": {},
     "execution_count": 78
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "source": [
    "plt.plot(np.array(j_history))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x202f2d97bb0>]"
      ]
     },
     "metadata": {},
     "execution_count": 73
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "source": [
    "o"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18, 7.80625564e-18, 7.80625564e-18,\n",
       "       7.80625564e-18, 7.80625564e-18])"
      ]
     },
     "metadata": {},
     "execution_count": 74
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "source": [
    "def mse_loss(y, pred):\r\n",
    "    return np.mean((y - pred)**2)\r\n",
    "\r\n",
    "def logistic_loss(y, pred):\r\n",
    "    return np.mean(-y * np.log(pred) - (1-y)* np.log(1-pred))\r\n",
    "\r\n",
    "def softmas_loss(y, pred):\r\n",
    "    return - np.sum(y*np.log(pred))/y.shape[1]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "source": [
    "def percRosen(x, y, alpha=1):\r\n",
    "    w = np.zeros((x.shape[1]+1))\r\n",
    "    x_ = np.c_[np.ones(x.shape[0]),x]\r\n",
    "    y_out = []\r\n",
    "    for xi, yi in x_, y:\r\n",
    "        y_ = np.sign(w.T@xi)\r\n",
    "        ei = yi - y_\r\n",
    "        w += (alpha * ei) * xi         \r\n",
    "        y_out.append(y_)\r\n",
    "    j = -np.sum(y*y_out)\r\n",
    "    return w, np.array(y_out), j\r\n",
    "\r\n",
    "def adeline(x,y, alpha=1):\r\n",
    "    w = np.zeros(x.shape[1]+1)\r\n",
    "    x = np.c_[np.ones(x.shape[0]),x]\r\n",
    "    y_out = []\r\n",
    "    for xi, yi in x, y:\r\n",
    "       y_ = w.T@xi\r\n",
    "       ei = yi - y_       \r\n",
    "       w += (alpha * ei) * xi\r\n",
    "       y_out.append(np.sign(y_))\r\n",
    "    j = np.sum((y-y_out)**2)/(2 * x.shape[0])\r\n",
    "    return w, np.array(y_out), j"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "source": [
    "def percRosen(x, y, k=2, alpha=1):\r\n",
    "    w = np.zeros((k,x.shape[1]+1))\r\n",
    "    x_ = np.c_[np.ones(x.shape[0]),x]\r\n",
    "    y_out = []\r\n",
    "    for xi, yi in x_, y:\r\n",
    "        yk = []\r\n",
    "        for ki in range(k):\r\n",
    "            y_ = np.sign(w[ki].T@xi)\r\n",
    "            ei = yi - y_\r\n",
    "            w[ki] += (alpha * ei) * xi \r\n",
    "            yk.append(y_)\r\n",
    "        y_out.append(yk)\r\n",
    "    j = np.sum(np.max([0,-(y_out*y)],axis=1))\r\n",
    "    return w, np.array(y_out), j\r\n",
    "\r\n",
    "def adeline(x,y, k=2, alpha=1):\r\n",
    "    w = np.zeros(k,x.shape[1]+1)\r\n",
    "    x = np.c_[np.ones(x.shape[0]),x]\r\n",
    "    y_out = []\r\n",
    "    for xi, yi in x, y:\r\n",
    "        yk = []\r\n",
    "        for ki in range(k):\r\n",
    "            y_ = w[ki].T@xi\r\n",
    "            ei = yi - y_       \r\n",
    "            w[ki] += (alpha * ei) * xi\r\n",
    "            yk.append(np.sign(y_))\r\n",
    "        y_out.append(yk)\r\n",
    "    j = np.sum(np.sum((y-y_out)**2,axis=1))/(2 * x.shape[0])\r\n",
    "    return w, np.array(y_out), j\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}